
from typing import Dict, List, Optional, Tuple, Union

import cv2
import numpy as np
from PIL import ImageGrab, Image
import logging

from pathlib import Path
import sys
PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))
    
import pyautogui
from objet.utils.pyauto import locate_in_image
from objet.utils.calibration import bbox_from_region, load_coordinates
from objet.scanner.cards_recognition import (
    TemplateIndex,
    is_cover_me_cards, is_etat_player,
    is_card_present,
    recognize_number_and_suit,is_cover
)
from objet.scanner.amount_ocr import OcrEngine

DEFAULT_COORD_PATH = Path("config/PMU/coordinates.json")
DEFAULT_ANCHOR_PATH = Path("config/PMU/anchor.png")
DEFAULT_CARDS_ROOT = Path("config/PMU/Cards")
DEFAULT_LOSE_PATH = Path("config/PMU/lose.png")


class ScanTable:
    """Scan de la table PMU basé sur capture écran + pyautogui.

    - Localisation de la fenêtre via un template d'ancre (me.png) avec locate_in_image().
    - ``screen_array`` conserve la capture plein écran en BGR (convention OpenCV).
    """

    def __init__(self, *, value_threshold: float = 0.75, suit_threshold: float = 0.75) -> None:
        # --- Config / calibration ---
        self.coord_path = DEFAULT_COORD_PATH

        # Gabarit de référence (ancre) utilisé par pyautogui/locate
        self.reference_pil: Image.Image = Image.open(DEFAULT_ANCHOR_PATH).convert("RGB")

        # --- État runtime ---
        self.value_threshold = value_threshold
        self.suit_threshold = suit_threshold
        self.screen_array: Optional[np.ndarray] = None     # plein écran, BGR
        self.anchor_box: Optional[Tuple[int, int, int, int]] = None
        self.scan_string: str = "init"
        self.cards_root = DEFAULT_CARDS_ROOT
        self.template_index = TemplateIndex(self.cards_root)
        self.template_index.load()
        
        regions, _, _ = load_coordinates(self.coord_path)
        self.player_state_boxes = bbox_from_region(regions.get("player_state_me"))
        self.ocr =  OcrEngine()

        # Première capture
        self.screen_refresh()
        

        

    
    def test_scan(self) -> bool:
        self.screen_refresh()
        if self.is_lose():
            sys.exit("You lose")
        return self.find_table()
    
    def screen_refresh(self) -> None:
        """Capture plein écran dans self.screen_array (numpy BGR)."""
        grab = ImageGrab.grab()               # PIL RGB
        rgb = np.array(grab)                  # numpy RGB
        self.screen_array = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)  # numpy BGR
        self.anchor_box = None

    # ------------------------------------------------------------------
    # Localisation de la table via pyautogui
    # ------------------------------------------------------------------
    def find_table(self, *, grayscale: bool = True, confidence: float = 0.9) -> bool:
        """Localise la table via l'ancre.

        Met à jour :
          - ``self.anchor_box`` avec la bounding box de l'ancre (left, top, w, h)
          - ``self.scan_string`` : 'ok' ou "don't find".
        """
        if self.screen_array is None:
            self.scan_string = "no_screen"
            self.anchor_box = None
            return False

        # 1) Localiser l'ancre dans le plein écran via pyautogui
        try:
            box = locate_in_image(
                haystack=self.screen_array,
                needle=self.reference_pil,
                assume_bgr=True,
                grayscale=grayscale,
                confidence=confidence,
            )
        except pyautogui.ImageNotFoundException:
            self.scan_string = "don't find"
            self.anchor_box = None
            return False

        anchor_left, anchor_top, anchor_w, anchor_h = box
        self.anchor_box = (int(anchor_left), int(anchor_top), int(anchor_w), int(anchor_h))
        self.scan_string = "ok"
        return True

    # ------------------------------------------------------------------
    # Scan des cartes directement sur la capture plein écran
    # ------------------------------------------------------------------

    def scan_carte(
        self,
        position_value: Tuple[int, int, int, int],
        position_suit: Tuple[int, int, int, int],
        *,
        template_set: Optional[str] = None,
    ) -> Tuple[Optional[str], Optional[str], float, float]:
        """
        Retourne:
            (value, suit, confidence_value, confidence_suit)

        - value, suit : str ou None
        - confidence_* : float entre 0.0 et 1.0
        """
        # crops séparés pour la valeur et le symbole
        image_card_value = self._extract_patch(position_value)
        image_card_suit = self._extract_patch(position_suit)


        if template_set == "hand" and self._should_skip_for_fold(image_card_value):
            return None, None, 0.0, 0.0

        if is_card_present(image_card_value):
                
        
            carte_value, carte_suit, score_value, score_suit = recognize_number_and_suit(
                image_card_value,
                image_card_suit,
                self.template_index,
                template_set=template_set,
            )

            conf_val = float(max(0.0, score_value or 0.0))
            conf_suit = float(max(0.0, score_suit or 0.0))

            value_ok = carte_value if (carte_value and conf_val >= self.value_threshold) else None
            suit_ok = carte_suit if (carte_suit and conf_suit >= self.suit_threshold) else None

            return value_ok, suit_ok, conf_val, conf_suit
        return None, None, 0.0, 0.0



    def _should_skip_for_fold(self,number_patch: np.ndarray) -> bool:
        state_patch = self._extract_patch(self.player_state_boxes, pad=0)
        return  is_cover_me_cards(state_patch, threshold=0.6)
        
       

    @staticmethod
    def _patch_has_pixels(patch: Union[np.ndarray, Image.Image]) -> bool:
        if isinstance(patch, np.ndarray):
            return patch.size > 0 and patch.ndim >= 2 and patch.shape[0] > 0 and patch.shape[1] > 0
        if isinstance(patch, Image.Image):
            width, height = patch.size
            return width > 0 and height > 0
        return False




    def scan_player(self, position_money,position_etat):
        etat = is_etat_player(self._extract_patch(position_etat))
        value = self.scan_money( position_money)       
        return etat, value

    def scan_money(self, position) -> Optional[float]:
        img = self._extract_patch(position)
        value, confidence, raw_text = self.ocr.read_amount(img)      
        return None if value is None else value


    def scan_bouton(self, position):
        return None, None


    def is_lose(self) -> bool:
        return is_cover(self.screen_array, DEFAULT_LOSE_PATH)
        
        
        
        
    def _extract_patch(self, box: Tuple[int, int, int, int], pad: int = 3) -> np.ndarray:
        """Retourne un crop (numpy BGR) pour ``box=(x,y,w,h)`` avec padding et clamp."""

        if self.screen_array is None:
            return np.empty((0, 0), dtype=np.uint8)

        x, y, w, h = box
        x = int(round(x))
        y = int(round(y))
        w = max(0, int(round(w)))
        h = max(0, int(round(h)))

        if w == 0 or h == 0:
            return np.empty((0, 0), dtype=np.uint8)

        x0 = max(0, int(x - pad))
        y0 = max(0, int(y - pad))

        h_scr, w_scr = self.screen_array.shape[:2]
        x1 = min(w_scr, int(x + w + pad))
        y1 = min(h_scr, int(y + h + pad))

        if x1 <= x0 or y1 <= y0:
            return np.empty((0, 0), dtype=np.uint8)

        img = self.screen_array[y0:y1, x0:x1].copy()
        return img

if __name__ == "__main__":
    scan = ScanTable()
    print(scan.test_scan())
    

    import cv2
    import numpy as np
    from PIL import Image

    img = scan.screen_array  # BGR

    if isinstance(img, np.ndarray):
        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        Image.fromarray(rgb).show()
    elif isinstance(img, Image.Image):
        img.show()
    else:
        print("Type d'image inattendu:", type(img))
        
